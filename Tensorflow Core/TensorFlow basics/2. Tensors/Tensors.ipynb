{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-02 11:47:09.718060: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512_VNNI\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensors** are the basic data structure of TensorFlow. They are similar to NumPy's ndarrays, with the addition being that Tensors can also be used on a GPU to accelerate computing.\n",
    "They are multi-dimensional arrays with a uniform type (called a dtype). They are immutable (can't be changed after they are created).\n",
    "You can see all the supported dtypes `tf.dtypes.DType`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics\n",
    "First, create some basic tensors:\n",
    "Here is a \"scalar\" or \"rank 0\" tensor. It has no axis or dimensions, and only a single value: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4, shape=(), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-02 11:47:13.379536: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512_VNNI\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-02 11:47:13.380943: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: \n"
     ]
    }
   ],
   "source": [
    "# This will be an int32 tensor by default, see `dtypes` for more info\n",
    "rank_0_tensor = tf.constant(4)\n",
    "print(rank_0_tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A \"vector\" or \"rank 1\" tensor. It has one axis, and is a list of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2. 3. 4.], shape=(3,), dtype=float16)\n"
     ]
    }
   ],
   "source": [
    "# Let's make this a float tensor explicitly\n",
    "rank_1_tensor = tf.constant([2.0, 3.0, 4.0], dtype=tf.float16)\n",
    "print(rank_1_tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A \"matrix\" or \"rank 2\" tensor. It has two axes, and is a list of lists of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]], shape=(3, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Create a rank 2 tensor (a matrix)\n",
    "rank_2_tensor = tf.constant([[1, 2],\n",
    "                            [3, 4],\n",
    "                            [5, 6]])\n",
    "print(rank_2_tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors can have any number of dimensions. Here is a \"rank 3\" tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0  1  2  3  4]\n",
      "  [ 5  6  7  8  9]]\n",
      "\n",
      " [[10 11 12 13 14]\n",
      "  [15 16 17 18 19]]\n",
      "\n",
      " [[20 21 22 23 24]\n",
      "  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "rank_3_tensor = tf.constant(\n",
    "    [[[0, 1, 2, 3, 4],\n",
    "      [5, 6, 7, 8, 9]],\n",
    "      [[10, 11, 12, 13, 14],\n",
    "       [15, 16, 17, 18, 19]],\n",
    "       [[20, 21, 22, 23, 24],\n",
    "        [25, 26, 27, 28, 29]]])\n",
    "\n",
    "print(rank_3_tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can convert a tensor to a NumPy array either using np.array or the tensor.numpy method. Tensors and NumPy arrays can be converted to each other. The conversion typically involves copying the underlying data. However, if the dtype and the shape match, the conversion is typically cheap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [5, 6]], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(rank_2_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [5, 6]], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_2_tensor.numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, you can create a tensor from anything that can be converted to a Tensor using tf.convert_to_tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int64, numpy=\n",
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [5, 6]])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.convert_to_tensor(np.array([[1, 2],[3, 4],[5, 6]]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do basic math on tensors, and the results are tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summation:  tf.Tensor(\n",
      "[[2 3]\n",
      " [4 5]], shape=(2, 2), dtype=int32)\n",
      "Subtraction:  tf.Tensor(\n",
      "[[0 1]\n",
      " [2 3]], shape=(2, 2), dtype=int32)\n",
      "Matrix Multiplication:  tf.Tensor(\n",
      "[[3 3]\n",
      " [7 7]], shape=(2, 2), dtype=int32)\n",
      "Dot Product:  tf.Tensor(\n",
      "[[3 3]\n",
      " [7 7]], shape=(2, 2), dtype=int32)\n",
      "Element-wise multiplication:  tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32)\n",
      "Element-wise division:  tf.Tensor(\n",
      "[[1. 2.]\n",
      " [3. 4.]], shape=(2, 2), dtype=float64)\n",
      "Element-wise exponentiation:  tf.Tensor(\n",
      "[[   1   32]\n",
      " [ 243 1024]], shape=(2, 2), dtype=int32)\n",
      "Element-wise square root:  tf.Tensor(\n",
      "[[1.         1.41421356]\n",
      " [1.73205081 2.        ]], shape=(2, 2), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[1, 2],\n",
    "                 [3, 4]])\n",
    "b = tf.constant([[1, 1],\n",
    "                 [1, 1]])\n",
    "\n",
    "print('Summation: ', a + b) # or tf.add(a, b)\n",
    "print('Subtraction: ', a - b) # or tf.subtract(a, b)\n",
    "print('Matrix Multiplication: ', a @ b) # or tf.matmul(a, b)\n",
    "print('Dot Product: ', tf.tensordot(a, b, axes=1)) # or tf.reduce_sum(a * b, axis=1)\n",
    "print('Element-wise multiplication: ', a * b) # or tf.multiply(a, b)\n",
    "print('Element-wise division: ', a / b) # or tf.divide(a, b)\n",
    "print('Element-wise exponentiation: ', a ** 5) # or tf.pow(a, 5)\n",
    "print('Element-wise square root: ', tf.sqrt(tf.cast(a, dtype=tf.float64))) # or tf.pow(a, 0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors are used in all kinds of operations in TensorFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "tf.Tensor([1 0], shape=(2,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[2.6894143e-01 7.3105860e-01]\n",
      " [9.9987662e-01 1.2339458e-04]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "c = tf.constant([[4.0, 5.0], [10.0, 1.0]])\n",
    "\n",
    "# Find the largest value\n",
    "print(tf.reduce_max(c))\n",
    "# Find the index of the largest value\n",
    "print(tf.math.argmax(c))\n",
    "# Compute the softmax\n",
    "print(tf.nn.softmax(c))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About shapes\n",
    "A tensor's shape is the number of elements in each dimension. The i-th element of the shape tuple is the length of the tensor along the i-th dimension.\n",
    "The length of the shape tuple, i.e., the number of tensor axes, is the tensor's rank, or number of dimensions. \n",
    "The size of a tensor is the total number of scalars it contains. This is the product of the elements of the shape tuple.\n",
    "\n",
    "TensorFlow automatically infers shapes during graph construction. These inferred shapes might have known or unknown rank. If the rank is known, the sizes of each dimension might be known or unknown.\n",
    "\n",
    "Tensors and `tf.TensorShape` objects have a `shape` property that returns a `TensorShape` object. This object can be used to query the rank and dimensions of the tensor. If the rank is known, the dimensions are also known. If the rank is unknown, the dimensions are unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of every element: <dtype: 'float32'>\n",
      "Number of dimensions (rank): 4\n",
      "Shape of tensor: (3, 2, 4, 5)\n",
      "Elements along axis 0 of tensor: 3\n",
      "Elements along the last axis of tensor: 5\n",
      "Total number of elements (3*2*4*5):  120\n"
     ]
    }
   ],
   "source": [
    "rank_4_tensor = tf.zeros([3, 2, 4, 5])\n",
    "\n",
    "print('Type of every element:', rank_4_tensor.dtype)\n",
    "print('Number of dimensions (rank):', rank_4_tensor.ndim)\n",
    "print('Shape of tensor:', rank_4_tensor.shape)\n",
    "print('Elements along axis 0 of tensor:', rank_4_tensor.shape[0])\n",
    "print('Elements along the last axis of tensor:', rank_4_tensor.shape[-1])\n",
    "print('Total number of elements (3*2*4*5): ', tf.size(rank_4_tensor).numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But note that the `Tensor.ndim` and `Tensor.shape` attributes don't return Tensor objects. If you need a Tensor use the `tf.rank` or `tf.shape` function. This difference is subtle, but it can be important when building graphs (later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor([3 2 4 5], shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.rank(rank_4_tensor))\n",
    "print(tf.shape(rank_4_tensor))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While axes are often referred to by their indices, you should always keep track of the meaning of each. Often axes are ordered from global to local: the **batch axis** first, followed by **spatial dimensions**, and **features for each location** last. This way feature vectors are contiguous regions of memory."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors often contain floats, but can also contain many other types such as booleans or strings.\n",
    "The base tf.Tensor class requires tensors to be *\"rectangular\"*, meaning that all the \"rows\" must have the same length. However, there are subclasses of tf.Tensor that allow for more flexible shapes. For example, `tf.SparseTensor` allows for sparse tensors that only store non-zero values and their indices, and `tf.RaggedTensor` allows for tensors with ragged dimensions (ragged dimensions are dimensions where all the slices along the dimension don't have the same size)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing\n",
    "### Single-axis indexing\n",
    "Tensors can be indexed just like Python lists or NumPy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_1_tensor = tf.constant([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First: 1\n",
      "Second: 2\n",
      "Last: 10\n",
      "Everything: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "Before 4: [1 2 3 4]\n",
      "From 4 to the end: [ 5  6  7  8  9 10]\n",
      "From 2, before 7: [3 4 5 6 7]\n",
      "Every other item: [1 3 5 7 9]\n",
      "Reversed: [10  9  8  7  6  5  4  3  2  1]\n"
     ]
    }
   ],
   "source": [
    "print(\"First:\", rank_1_tensor[0].numpy())\n",
    "print(\"Second:\", rank_1_tensor[1].numpy())\n",
    "print(\"Last:\", rank_1_tensor[-1].numpy())\n",
    "\n",
    "print(\"Everything:\", rank_1_tensor[:].numpy())\n",
    "print(\"Before 4:\", rank_1_tensor[:4].numpy())\n",
    "print(\"From 4 to the end:\", rank_1_tensor[4:].numpy())\n",
    "print(\"From 2, before 7:\", rank_1_tensor[2:7].numpy())\n",
    "print(\"Every other item:\", rank_1_tensor[::2].numpy())\n",
    "print(\"Reversed:\", rank_1_tensor[::-1].numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-axis indexing\n",
    "You can index multiple axes at once, using a comma-separated list of indices or slices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_2_tensor = tf.constant([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                             [11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
    "                             [21, 22, 23, 24, 25, 26, 27, 28, 29, 30]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "[[11 12 13 14 15 16 17 18 19 20]\n",
      " [21 22 23 24 25 26 27 28 29 30]]\n",
      "[ 3 13 23]\n",
      "[[ 1  2  3  4  5  6  7  8  9 10]\n",
      " [21 22 23 24 25 26 27 28 29 30]]\n"
     ]
    }
   ],
   "source": [
    "# Pull out a single value from a 2-rank tensor\n",
    "print(rank_2_tensor[1, 1].numpy())\n",
    "\n",
    "# Pull out a submatrix from a 2-rank tensor\n",
    "print(rank_2_tensor[1:, :].numpy())\n",
    "\n",
    "# Pull out a single column from a 2-rank tensor\n",
    "print(rank_2_tensor[:, 2].numpy())\n",
    "\n",
    "# Skip every other row\n",
    "print(rank_2_tensor[::2, :].numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating shapes\n",
    "Reshaping is the process of changing the number of rows and columns in a tensor. You can use the `tf.reshape` function to do this. For example, here is a 3x2 tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]], shape=(3, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1, 2],[3, 4],[5, 6]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2]\n"
     ]
    }
   ],
   "source": [
    "# You can convert the shape to a list with the `as_list` method:\n",
    "print(x.shape.as_list())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can reshape a tensor into a new shape. The `tf.reshape` operation is fast and cheap, since it doesn't require copying any data. However, since it only rearranges the existing data, the new tensor must have the same number of elements as the original tensor. \n",
    "The data maintains its layout in memory and a new tensor is created, with the requested shape, pointing to the same data. TensorFlow uses C-style \"row-major\" memory ordering, where incrementing the rightmost index corresponds to a single step in memory.\n",
    "\n",
    "Thus, the following code will fail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2 3]\n",
      " [4 5 6]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# You can reshape a tensor to a new shape. Note that you're passing in a list\n",
    "reshaped = tf.reshape(x, [2, 3])\n",
    "print(reshaped)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you flatten a tensor you can see what order it is laid out in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]], shape=(3, 2), dtype=int32)\n",
      "Reshaped: tf.Tensor([1 2 3 4 5 6], shape=(6,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# A \"-1\" in the shape means \"whatever fits\". The effect is the same as if flattened\n",
    "print(\"Original:\", x)\n",
    "print(\"Reshaped:\", tf.reshape(x, [-1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data **maintains its layout** in memory and **a new tensor** is created, with the **requested shape**, pointing to the same data. TensorFlow uses C-style \"row-major\" memory ordering, where incrementing the rightmost index corresponds to a single step in memory."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Typically the only reasonable use of tf.reshape is to combine or split adjacent axes (or add/remove 1s).\n",
    "\n",
    "For this 3x2x5 tensor, reshaping to (3x2)x5 or 3x(2x5) are both reasonable things to do, as the slices do not mix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tf.Tensor(\n",
      "[[[ 0  1  2  3  4]\n",
      "  [ 5  6  7  8  9]]\n",
      "\n",
      " [[10 11 12 13 14]\n",
      "  [15 16 17 18 19]]\n",
      "\n",
      " [[20 21 22 23 24]\n",
      "  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)\n",
      "\n",
      "Reshaped tf.Tensor(\n",
      "[[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]\n",
      " [15 16 17 18 19]\n",
      " [20 21 22 23 24]\n",
      " [25 26 27 28 29]], shape=(6, 5), dtype=int32)\n",
      "\n",
      "Reshaped tf.Tensor(\n",
      "[[ 0  1  2  3  4  5  6  7  8  9]\n",
      " [10 11 12 13 14 15 16 17 18 19]\n",
      " [20 21 22 23 24 25 26 27 28 29]], shape=(3, 10), dtype=int32)\n",
      "\n",
      "Reshaped tf.Tensor(\n",
      "[[ 0  1  2  3  4  5  6  7  8  9]\n",
      " [10 11 12 13 14 15 16 17 18 19]\n",
      " [20 21 22 23 24 25 26 27 28 29]], shape=(3, 10), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(\"Original\", rank_3_tensor)\n",
    "print(\"\\nReshaped\", tf.reshape(rank_3_tensor, [3*2, 5]))\n",
    "print(\"\\nReshaped\", tf.reshape(rank_3_tensor, [3, 2*5]))\n",
    "print(\"\\nReshaped\", tf.reshape(rank_3_tensor, [3, -1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshaping will \"work\" for any new shape with the same total number of elements, but it will not do anything useful if you do not respect the order of the axes.\n",
    "\n",
    "Swapping axes in tf.reshape does not work; you need tf.transpose for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0  1  2  3  4]\n",
      "  [ 5  6  7  8  9]\n",
      "  [10 11 12 13 14]]\n",
      "\n",
      " [[15 16 17 18 19]\n",
      "  [20 21 22 23 24]\n",
      "  [25 26 27 28 29]]], shape=(2, 3, 5), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[ 0  1  2  3  4  5]\n",
      " [ 6  7  8  9 10 11]\n",
      " [12 13 14 15 16 17]\n",
      " [18 19 20 21 22 23]\n",
      " [24 25 26 27 28 29]], shape=(5, 6), dtype=int32) \n",
      "\n",
      "InvalidArgumentError: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input to reshape is a tensor with 30 values, but the requested shape requires a multiple of 7 [Op:Reshape]\n"
     ]
    }
   ],
   "source": [
    "# Bad examples: don't do this\n",
    "\n",
    "# You can't reorder axes with reshape.\n",
    "print(tf.reshape(rank_3_tensor, [2, 3, 5]), \"\\n\") \n",
    "\n",
    "# This is a mess\n",
    "print(tf.reshape(rank_3_tensor, [5, 6]), \"\\n\")\n",
    "\n",
    "# This doesn't work at all\n",
    "try:\n",
    "  tf.reshape(rank_3_tensor, [7, -1])\n",
    "except Exception as e:\n",
    "  print(f\"{type(e).__name__}: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to reorder the axes, you can use `tf.transpose`. It takes a tensor and a permutation of the dimensions. The returned tensor has the same values as the input, but its axes are permuted in the order specified by the permutation argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: tf.Tensor(\n",
      "[[[ 0  1  2  3  4]\n",
      "  [ 5  6  7  8  9]]\n",
      "\n",
      " [[10 11 12 13 14]\n",
      "  [15 16 17 18 19]]\n",
      "\n",
      " [[20 21 22 23 24]\n",
      "  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)\n",
      "\n",
      "Transposed: tf.Tensor(\n",
      "[[[ 0  1  2  3  4]\n",
      "  [10 11 12 13 14]\n",
      "  [20 21 22 23 24]]\n",
      "\n",
      " [[ 5  6  7  8  9]\n",
      "  [15 16 17 18 19]\n",
      "  [25 26 27 28 29]]], shape=(2, 3, 5), dtype=int32)\n",
      "\n",
      "Transposed: tf.Tensor(\n",
      "[[[ 0 10 20]\n",
      "  [ 5 15 25]]\n",
      "\n",
      " [[ 1 11 21]\n",
      "  [ 6 16 26]]\n",
      "\n",
      " [[ 2 12 22]\n",
      "  [ 7 17 27]]\n",
      "\n",
      " [[ 3 13 23]\n",
      "  [ 8 18 28]]\n",
      "\n",
      " [[ 4 14 24]\n",
      "  [ 9 19 29]]], shape=(5, 2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(\"Original:\", rank_3_tensor)\n",
    "print(\"\\nTransposed:\", tf.transpose(rank_3_tensor, perm=[1, 0, 2]))\n",
    "print(\"\\nTransposed:\", tf.transpose(rank_3_tensor, perm=[2, 1, 0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the `tf.squeeze` function to remove dimensions of size 1, and the `tf.expand_dims` function to add dimensions of size 1. For example, here is a 3x1x2x1 tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: tf.Tensor(\n",
      "[[[[0]\n",
      "   [1]]]\n",
      "\n",
      "\n",
      " [[[2]\n",
      "   [3]]]\n",
      "\n",
      "\n",
      " [[[4]\n",
      "   [5]]]], shape=(3, 1, 2, 1), dtype=int32)\n",
      "\n",
      "Squeezed: tf.Tensor(\n",
      "[[0 1]\n",
      " [2 3]\n",
      " [4 5]], shape=(3, 2), dtype=int32)\n",
      "\n",
      "Expanded: tf.Tensor(\n",
      "[[[[[0]\n",
      "    [1]]]\n",
      "\n",
      "\n",
      "  [[[2]\n",
      "    [3]]]\n",
      "\n",
      "\n",
      "  [[[4]\n",
      "    [5]]]]], shape=(1, 3, 1, 2, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "tensor_3121 = tf.constant([0,1,2,3,4,5], shape=(3, 1, 2 , 1))\n",
    "print(\"Original:\", tensor_3121)\n",
    "print(\"\\nSqueezed:\", tf.squeeze(tensor_3121))\n",
    "print(\"\\nExpanded:\", tf.expand_dims(tensor_3121, axis=0))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may run across not-fully-specified shapes. Either the shape contains a None (an axis-length is unknown) or the whole shape is None (the rank of the tensor is unknown).\n",
    "\n",
    "Except for `tf.RaggedTensor`, such shapes will only occur in the context of TensorFlow's symbolic, graph-building APIs:\n",
    "\n",
    "* tf.function\n",
    "* The keras functional API."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More on DTypes\n",
    "A tf.Tensor has a datatype (called a tf.DType).\n",
    "To inspect a `tf.Tensor`'s data type use the `Tensor.dtype` property.\n",
    "\n",
    "When creating a `tf.Tensor` from a Python object you may optionally specify the datatype.\n",
    "\n",
    "If you don't, TensorFlow chooses a datatype that can represent your data. TensorFlow converts Python integers to `tf.int32` and Python floating point numbers to `tf.float32`. Otherwise TensorFlow uses the same rules NumPy uses when converting to arrays, as described in the [NumPy dtypes documentation](https://numpy.org/doc/stable/user/basics.types.html).\n",
    "\n",
    "You can explicitly convert a `tf.Tensor` from one datatype to another using `Tensor.cast`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f64: tf.Tensor([1.1 2.2 3.3], shape=(3,), dtype=float64)\n",
      "f32 tf.Tensor([1.1 2.2 3.3], shape=(3,), dtype=float32)\n",
      "f64 as uint8: tf.Tensor([1 2 3], shape=(3,), dtype=uint8)\n",
      "From np.array: tf.Tensor([1.1 2.2 3.3], shape=(3,), dtype=float16)\n"
     ]
    }
   ],
   "source": [
    "the_f64_tensor = tf.constant([1.1, 2.2, 3.3], dtype=tf.float64)\n",
    "print(\"f64:\", the_f64_tensor)\n",
    "\n",
    "the_f32_tensor = tf.cast(the_f64_tensor, dtype=tf.float32)\n",
    "print(\"f32\", the_f32_tensor)\n",
    "\n",
    "# Loss of precision\n",
    "print(\"f64 as uint8:\", tf.cast(the_f64_tensor, dtype=tf.uint8))\n",
    "\n",
    "# You can also cast a NumPy array or a Python list\n",
    "the_f16_tensor = tf.cast(np.array([1.1, 2.2, 3.3]), dtype=tf.float16)\n",
    "print(\"From np.array:\", the_f16_tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting\n",
    "\n",
    "Broadcasting is a powerful mechanism that allows TensorFlow to work with tensors of different shapes when performing arithmetic operations. The term broadcasting was first used by [Numpy](https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html).\n",
    "\n",
    "In short, under certain conditions, smaller tensors are \"stretched\" automatically to fit larger tensors when running combined operations on them.\n",
    "The simplest and most common case is when you attempt to multiply or add a tensor to a scalar. In that case, the scalar is broadcast to be the same shape as the other argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x + 2 =  tf.Tensor([3 4 5], shape=(3,), dtype=int32)\n",
      "x + y =  tf.Tensor([3 4 5], shape=(3,), dtype=int32)\n",
      "x + z =  tf.Tensor([3 4 5], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([1, 2, 3])\n",
    "\n",
    "y = tf.constant(2)\n",
    "z = tf.constant([2, 2, 2])\n",
    "\n",
    "# Element-wise addition, all produce the same result\n",
    "print('x + 2 = ', x + 2)\n",
    "print('x + y = ', x + y)\n",
    "print('x + z = ', x + z)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, axes with length 1 can be stretched out to match the other arguments. Both arguments can be stretched in the same computation.\n",
    "\n",
    "In this case a 3x1 matrix is element-wise multiplied by a 1x4 matrix to produce a 3x4 matrix. Note how the leading 1 is optional: The shape of y is [4]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1]\n",
      " [2]\n",
      " [3]], shape=(3, 1), dtype=int32) \n",
      "\n",
      "tf.Tensor([1 2 3 4], shape=(4,), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[ 1  2  3  4]\n",
      " [ 2  4  6  8]\n",
      " [ 3  6  9 12]], shape=(3, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.reshape(x, (3, 1))\n",
    "y = tf.range(1, 5) # this is actually a vector, a tensor with a single dimension (4,) that will be stretched\n",
    "\n",
    "# element-wise multiplication\n",
    "print(x, '\\n')\n",
    "print(y, '\\n')\n",
    "print(tf.multiply(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 1 1 1]\n",
      " [2 2 2 2]\n",
      " [3 3 3 3]], shape=(3, 4), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[1 2 3 4]\n",
      " [1 2 3 4]\n",
      " [1 2 3 4]], shape=(3, 4), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[ 1  2  3  4]\n",
      " [ 2  4  6  8]\n",
      " [ 3  6  9 12]], shape=(3, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Which is equivalent to\n",
    "x_stretched = tf.constant([[1, 1, 1, 1],\n",
    "                           [2, 2, 2, 2],\n",
    "                           [3, 3, 3, 3]])\n",
    "\n",
    "y_stretched = tf.constant([[1, 2, 3, 4],\n",
    "                           [1, 2, 3, 4],\n",
    "                           [1, 2, 3, 4]])\n",
    "\n",
    "print(x_stretched, '\\n')\n",
    "print(y_stretched, '\\n')\n",
    "\n",
    "print(x_stretched * y_stretched) # element-wise multiplication, operator overloading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time, broadcasting is both time and space efficient, as the broadcast operation **never materializes the expanded tensors in memory**.\n",
    "\n",
    "You see what broadcasting looks like using `tf.broadcast_to`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2 3]\n",
      " [1 2 3]\n",
      " [1 2 3]], shape=(3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.broadcast_to(tf.constant([1, 2, 3]), shape=(3, 3)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike a mathematical op, for example, broadcast_to does nothing special to save memory. Here, you are materializing the tensor."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.convert_to_tensor\n",
    "\n",
    "Most ops, like `tf.matmul` and `tf.reshape` take arguments of class tf.Tensor. However, you'll notice in the above case, Python objects shaped like tensors are accepted.\n",
    "\n",
    "Most, but not all, ops call convert_to_tensor on non-tensor arguments. There is a registry of conversions, and most object classes like NumPy's ndarray, TensorShape, Python lists, and tf.Variable will all convert automatically.\n",
    "\n",
    "See `tf.register_tensor_conversion_function` for more details, and if you have your own type you'd like to automatically convert to a tensor."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ragged Tensor\n",
    "\n",
    "A tensor with variable numbers of elements along one axis is called \"ragged\". Use `tf.RaggedTensor` to represent them.\n",
    "You can create a `tf.RaggedTensor` from a nested Python list of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2], [3, 4, 5], [6], [], [7]]\n",
      "ValueError: Can't convert non-rectangular Python sequence to Tensor.\n",
      "<tf.RaggedTensor [[1, 2], [3, 4, 5], [6], [], [7]]>\n",
      "(5, None)\n"
     ]
    }
   ],
   "source": [
    "ragged_list = [[1, 2], [3, 4, 5], [6], [], [7]]\n",
    "print(ragged_list)\n",
    "\n",
    "try:\n",
    "    tensor = tf.constant(ragged_list)\n",
    "except Exception as e:\n",
    "    print(f\"{type(e).__name__}: {e}\")\n",
    "\n",
    "ragged_tensor = tf.ragged.constant(ragged_list)\n",
    "print(ragged_tensor)\n",
    "print(ragged_tensor.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String Tensors\n",
    "\n",
    "`tf.string` is a dtype, which is to say you can represent data as strings (variable-length byte arrays) in tensors.\n",
    "\n",
    "The strings are atomic and cannot be indexed the way Python strings are. The length of the string is not one of the axes of the tensor. See `tf.strings` for functions to manipulate them.\n",
    "\n",
    "Here is a scalar string tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'Gray wolf', shape=(), dtype=string)\n",
      "tf.Tensor([b'Gray wolf' b'Quick brown fox' b'Lazy dog'], shape=(3,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "scalar_string_tensor = tf.constant(\"Gray wolf\")\n",
    "print(scalar_string_tensor)\n",
    "\n",
    "tensor_of_strings = tf.constant([\"Gray wolf\",\n",
    "                             \"Quick brown fox\",\n",
    "                             \"Lazy dog\"])\n",
    "print(tensor_of_strings) # it is a vector of strings, and the shape is (3,)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above printout the b prefix indicates that tf.string dtype is not a unicode string, but a byte-string. See the [Unicode Tutorial](https://www.tensorflow.org/tutorials/load_data/unicode) for more about working with unicode text in TensorFlow.\n",
    "\n",
    "If you pass unicode characters they are utf-8 encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'\\xf0\\x9f\\xa5\\xb3\\xf0\\x9f\\x91\\x8d'>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(\"ü•≥üëç\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some basic functions are available in `tf.strings`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(9, shape=(), dtype=int32)\n",
      "tf.Tensor([ 9 15  8], shape=(3,), dtype=int32)\n",
      "tf.Tensor([ 71 114  97 121  32 119 111 108 102], shape=(9,), dtype=int32)\n",
      "tf.Tensor([b'Gray' b'wolf'], shape=(2,), dtype=string)\n",
      "<tf.RaggedTensor [[b'Gray', b'wolf'], [b'Quick', b'brown', b'fox'], [b'Lazy', b'dog']]>\n",
      "tf.Tensor(b'Gray ', shape=(), dtype=string)\n",
      "tf.Tensor([  1  10 100], shape=(3,), dtype=int32)\n",
      "<tf.RaggedTensor [[b'1'], [b'1', b'0'], [b'1', b'0', b'0']]>\n",
      "tf.Tensor([49 32 49 48 32 49 48 48], shape=(8,), dtype=uint8)\n",
      "tf.Tensor([b'\\xf0\\x9f\\xa5\\xb3' b'\\xf0\\x9f\\x91\\x8d'], shape=(2,), dtype=string)\n",
      "<tf.RaggedTensor [[b'\\xf0\\x9f\\xa5\\xb3'],\n",
      " [b'\\xf0\\x9f\\x91\\x8d']]>\n",
      "<tf.RaggedTensor [[129395],\n",
      " [128077]]>\n"
     ]
    }
   ],
   "source": [
    "print(tf.strings.length(scalar_string_tensor))\n",
    "print(tf.strings.length(tensor_of_strings, unit=\"UTF8_CHAR\"))\n",
    "\n",
    "# Decode the string into a vector of Unicode code points\n",
    "print(tf.strings.unicode_decode(scalar_string_tensor, \"UTF-8\"))\n",
    "\n",
    "# Split a string into a vector of strings\n",
    "print(tf.strings.split(scalar_string_tensor, sep=\" \"))\n",
    "print(tf.strings.split(tensor_of_strings, sep=\" \")) # returns a ragged tensor\n",
    "\n",
    "# Get the first 5 characters\n",
    "print(tf.strings.substr(scalar_string_tensor, pos=0, len=5))\n",
    "\n",
    "# Convert to numbers\n",
    "numbers = tf.constant('1 10 100')\n",
    "print(tf.strings.to_number(tf.strings.split(numbers, sep=' '), out_type=tf.int32))\n",
    "\n",
    "# Convert to bytes\n",
    "byte_strings = tf.strings.bytes_split(tf.strings.split(numbers, sep=' '))\n",
    "print(byte_strings)\n",
    "byte_ints = tf.io.decode_raw(tf.constant('1 10 100'), tf.uint8)\n",
    "print(byte_ints)\n",
    "\n",
    "# Split as unicode code points and then decode it\n",
    "unicode_bytes = tf.constant(['ü•≥', 'üëç']) # a vector of byte-strings\n",
    "print(unicode_bytes)\n",
    "unicode_char_bytes = tf.strings.unicode_split(unicode_bytes, input_encoding='UTF-8')\n",
    "print(unicode_char_bytes)\n",
    "unicode_chars = tf.strings.unicode_decode(unicode_bytes, input_encoding='UTF-8')\n",
    "print(unicode_chars)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `tf.string` dtype is used for all raw bytes data in TensorFlow. The `tf.io` module contains functions for converting data to and from bytes, including decoding images and parsing csv."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse Tensors\n",
    "A `tf.SparseTensor` represents a set of sparse indices and a corresponding array of values. The tensor is dense if all values are specified, but it is sparse if only a subset of values are specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 1]\n",
      " [1 0]\n",
      " [2 3]], shape=(3, 2), dtype=int64), values=tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64)) \n",
      "\n",
      "tf.Tensor(\n",
      "[[0. 1. 0. 0.]\n",
      " [2. 0. 0. 0.]\n",
      " [0. 0. 0. 3.]], shape=(3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "sparse_tensor = tf.sparse.SparseTensor(indices=[[0, 1], [1, 0], [2, 3]],\n",
    "                                       values=[1., 2., 3.],\n",
    "                                       dense_shape=[3, 4])\n",
    "\n",
    "print(sparse_tensor, '\\n')\n",
    "\n",
    "# Convert to dense tensor\n",
    "print(tf.sparse.to_dense(sparse_tensor))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3da73983a67b104596d006960b22d6935bc5ef99c85b6c0f2acbfe841677b310"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
