{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Variables\n",
    "\n",
    "A TensorFlow **variable** is the recommended way to represent shared, persistent state your program manipulates. This guide covers how to create, update, and manage instances of `tf.Variable` in TensorFlow.\n",
    "\n",
    "Variables are created and tracked via the `tf.Variable` class. A `tf.Variable` represents a tensor whose value can be changed by running ops on it. Specific ops allow you to read and modify the values of this tensor. Higher level libraries like `tf.keras` use `tf.Variable` to store model parameters. This guide covers how to create, update, and manage instances of `tf.Variable` in TensorFlow."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-02 12:56:46.271766: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512_VNNI\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# tf.debugging.set_log_device_placement(True) # To see which device is used for each operation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a variable\n",
    "\n",
    "A variable is created by passing an initial value to the `tf.Variable` constructor. The initial value defines the type and shape of the variable. After construction, the type and shape of the variable are fixed. The value can be read using the `read_value` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor:  tf.Tensor(\n",
      "[[1. 2.]\n",
      " [3. 4.]], shape=(2, 2), dtype=float32)\n",
      "\n",
      "Variable:  <tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[1., 2.],\n",
      "       [3., 4.]], dtype=float32)>\n",
      "\n",
      "Bool variable:  <tf.Variable 'Variable:0' shape=(4,) dtype=bool, numpy=array([False, False, False,  True])>\n",
      "\n",
      "Complex variable:  <tf.Variable 'Variable:0' shape=(2,) dtype=complex128, numpy=array([5.+4.j, 6.+1.j])>\n"
     ]
    }
   ],
   "source": [
    "my_tensor = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "my_variable = tf.Variable(my_tensor)\n",
    "bool_variable = tf.Variable([False, False, False, True])\n",
    "complex_variable = tf.Variable([5 + 4j, 6 + 1j])\n",
    "\n",
    "print(\"Tensor: \", my_tensor)\n",
    "print(\"\\nVariable: \", my_variable)\n",
    "print(\"\\nBool variable: \", bool_variable)\n",
    "print(\"\\nComplex variable: \", complex_variable)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variable looks and acts like a tensor, and, in fact, is a data structure backed by a `tf.Tensor`. Like tensors, they have a dtype and a shape, and can be exported to NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (2, 2)\n",
      "DType:  <dtype: 'float32'>\n",
      "As NumPy:  [[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape: \", my_variable.shape)\n",
    "print(\"DType: \", my_variable.dtype)\n",
    "print(\"As NumPy: \", my_variable.numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most tensor operations work on variables as expected, although variables **cannot be reshaped**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A variable: <tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[1., 2.],\n",
      "       [3., 4.]], dtype=float32)>\n",
      "\n",
      "Viewed as a tensor: tf.Tensor(\n",
      "[[1. 2.]\n",
      " [3. 4.]], shape=(2, 2), dtype=float32)\n",
      "\n",
      "Index of highest value: tf.Tensor([1 1], shape=(2,), dtype=int64)\n",
      "\n",
      "Copying and reshaping:  tf.Tensor([[1. 2. 3. 4.]], shape=(1, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(\"A variable:\", my_variable)\n",
    "print(\"\\nViewed as a tensor:\", tf.convert_to_tensor(my_variable))\n",
    "print(\"\\nIndex of highest value:\", tf.math.argmax(my_variable))\n",
    "\n",
    "# This creates a new tensor; it does not reshape the variable.\n",
    "print(\"\\nCopying and reshaping: \", tf.reshape(my_variable, [1,4]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noted above, variables are backed by tensors. You can reassign the variable using `tf.Variable.assign`. Calling **assign** does not (usually) allocate a new tensor; instead, the existing tensor's memory is reused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2, 2) dtype=int32, numpy=\n",
      "array([[0, 0],\n",
      "       [0, 0]], dtype=int32)>\n",
      "ValueError: Cannot assign value to variable ' Variable:0': Shape mismatch.The variable shape (2, 2), and the assigned value shape (4,) are incompatible.\n",
      "TypeError: Cannot convert [[1.1, 2.2], [3.3, 4.4]] to EagerTensor of dtype int32\n",
      "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[1., 2.],\n",
      "       [3., 4.]], dtype=float32)>\n",
      "[[1 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable([[1, 2], [3, 4]])\n",
    "\n",
    "# This will keep the same underlying tensor and the same dtype.\n",
    "a.assign([[0, 0], [0, 0]])\n",
    "print(a)\n",
    "\n",
    "# Not allowed as it resizes the variable: \n",
    "try:\n",
    "  a.assign([1, 2, 3, 4])\n",
    "except Exception as e:\n",
    "  print(f\"{type(e).__name__}: {e}\")\n",
    "\n",
    "# This is not allowed as it would change the dtype.\n",
    "try:\n",
    "    a.assign([[1.1, 2.2], [3.3, 4.4]])\n",
    "except Exception as e:\n",
    "    print(f\"{type(e).__name__}: {e}\")\n",
    "\n",
    "# However, if it is possible to cast the new value to the same dtype, it will work.\n",
    "b = tf.Variable([[1.1, 2.2], [3.3, 4.4]])\n",
    "b.assign([[1, 2], [3, 4]])\n",
    "print(b)\n",
    "\n",
    "# You can also assign_add() and assign_sub() to a variable.\n",
    "print(a.assign_add([[1, 1], [1, 1]]).numpy())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you use a variable like a tensor in operations, you will usually operate on the backing tensor.\n",
    "\n",
    "Creating new variables from existing variables **duplicates** the backing tensors. Two variables will not share the same memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0 1.0\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(1.0)\n",
    "b = tf.Variable(a)\n",
    "a.assign(2.0)\n",
    "\n",
    "print(a.numpy(), b.numpy()) # They are different!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lifecycle of a variable, naming and watching\n",
    "\n",
    "In Python-based TensorFlow, `tf.Variable` instance have the same **lifecycle** as other Python objects. When there are no references to a variable it is automatically deallocated.\n",
    "\n",
    "Variables can also be **named** which can help you track and debug them. You can give two variables the same name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_variable:0 my_variable:0\n",
      "tf.Tensor(\n",
      "[[False False]\n",
      " [False False]], shape=(2, 2), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(my_tensor, name=\"my_variable\")\n",
    "b = tf.Variable(my_tensor+1, name=\"my_variable\")\n",
    "\n",
    "# They have same name but different values\n",
    "print(a.name, b.name)\n",
    "print(a==b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable names are preserved when saving and loading models. By default, variables in models will acquire unique variable names automatically, so you don't need to assign them yourself unless you want to.\n",
    "\n",
    "Although variables are important for differentiation, some variables will not need to be differentiated. You can **turn off gradients** for a variable by setting `trainable` to `false` at creation. An example of a variable that would not need gradients is a training step counter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=1>\n"
     ]
    }
   ],
   "source": [
    "step_counter = tf.Variable(1, trainable=False)\n",
    "print(step_counter)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placing variables and tensors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For better performance, TensorFlow will attempt to place tensors and variables on the fastest device compatible with its dtype. This means most variables are placed on a GPU if one is available.\n",
    "\n",
    "However, you can override this. In this snippet, place a float tensor and a variable on the CPU, even if a GPU is available. By turning on device placement logging (see **Setup**), you can see where the variable is placed.\n",
    "\n",
    "Although manual placement works, using [distribution strategies](https://www.tensorflow.org/guide/distributed_training) can be a more convenient and scalable way to optimize your computation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run this notebook on different backends with and without a GPU you will see different logging. Note that logging device placement must be turned on at the start of the session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/job:localhost/replica:0/task:0/device:CPU:0\n",
      "/job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"CPU:0\"):\n",
    "    a = tf.Variable([1.0, 2.0, 3.0])\n",
    "    print(a.device)\n",
    "\n",
    "with tf.device(\"GPU:0\"):\n",
    "    b = tf.Variable([1.0, 2.0, 3.0])\n",
    "    print(b.device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's possible to set the location of a variable or tensor on one device and do the computation on another device. This will introduce delay, as data needs to be copied between the devices.\n",
    "\n",
    "You might do this, however, if you had multiple GPU workers but only want one copy of the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1.  4.  9.]\n",
      " [ 4. 10. 18.]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.device('CPU:0'):\n",
    "  a = tf.Variable([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "  b = tf.Variable([[1.0, 2.0, 3.0]])\n",
    "\n",
    "with tf.device('GPU:0'):\n",
    "  # Element-wise multiply\n",
    "  k = a * b\n",
    "\n",
    "print(k)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the full list of devices available to TensorFlow, run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3da73983a67b104596d006960b22d6935bc5ef99c85b6c0f2acbfe841677b310"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
